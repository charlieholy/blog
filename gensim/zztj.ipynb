{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/7c/tx2rnzzj2_x546cjtv31_6yr0000gn/T/jieba.cache\n",
      "Loading model cost 1.048 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "with open('./zztj.txt') as f:\n",
    "    document = f.read()\n",
    "    \n",
    "    #document_decode = document.decode('GBK')\n",
    "    \n",
    "    document_cut = jieba.cut(document)\n",
    "    #print ( ' '.join(document_cut))  #如果打印结果，则分词效果消失，后面的result无法显示\n",
    "    result = ' '.join(document_cut)\n",
    "    #result = result.encode('utf-8')\n",
    "    with open('./zztj_segment.txt', 'w') as f2:\n",
    "        f2.write(result)\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 08:51:57,924 : INFO : collecting all words and their counts\n",
      "2020-03-15 08:51:57,937 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-03-15 08:51:58,052 : INFO : PROGRESS: at sentence #10000, processed 199274 words, keeping 28745 word types\n",
      "2020-03-15 08:51:58,164 : INFO : PROGRESS: at sentence #20000, processed 397588 words, keeping 48194 word types\n",
      "2020-03-15 08:51:58,265 : INFO : PROGRESS: at sentence #30000, processed 597685 words, keeping 64009 word types\n",
      "2020-03-15 08:51:58,362 : INFO : PROGRESS: at sentence #40000, processed 795048 words, keeping 79627 word types\n",
      "2020-03-15 08:51:58,477 : INFO : PROGRESS: at sentence #50000, processed 989389 words, keeping 93505 word types\n",
      "2020-03-15 08:51:58,582 : INFO : PROGRESS: at sentence #60000, processed 1193064 words, keeping 107948 word types\n",
      "2020-03-15 08:51:58,667 : INFO : PROGRESS: at sentence #70000, processed 1392525 words, keeping 121970 word types\n",
      "2020-03-15 08:51:58,779 : INFO : PROGRESS: at sentence #80000, processed 1592220 words, keeping 135040 word types\n",
      "2020-03-15 08:51:58,870 : INFO : PROGRESS: at sentence #90000, processed 1788516 words, keeping 146953 word types\n",
      "2020-03-15 08:51:58,962 : INFO : PROGRESS: at sentence #100000, processed 1984122 words, keeping 157352 word types\n",
      "2020-03-15 08:51:59,047 : INFO : PROGRESS: at sentence #110000, processed 2174577 words, keeping 167553 word types\n",
      "2020-03-15 08:51:59,198 : INFO : PROGRESS: at sentence #120000, processed 2366935 words, keeping 177973 word types\n",
      "2020-03-15 08:51:59,323 : INFO : PROGRESS: at sentence #130000, processed 2565930 words, keeping 189368 word types\n",
      "2020-03-15 08:51:59,444 : INFO : PROGRESS: at sentence #140000, processed 2762821 words, keeping 200151 word types\n",
      "2020-03-15 08:51:59,559 : INFO : PROGRESS: at sentence #150000, processed 2957483 words, keeping 210130 word types\n",
      "2020-03-15 08:51:59,678 : INFO : PROGRESS: at sentence #160000, processed 3151576 words, keeping 220066 word types\n",
      "2020-03-15 08:51:59,789 : INFO : PROGRESS: at sentence #170000, processed 3348480 words, keeping 229231 word types\n",
      "2020-03-15 08:51:59,879 : INFO : PROGRESS: at sentence #180000, processed 3541298 words, keeping 238183 word types\n",
      "2020-03-15 08:51:59,977 : INFO : PROGRESS: at sentence #190000, processed 3731414 words, keeping 246828 word types\n",
      "2020-03-15 08:52:00,081 : INFO : PROGRESS: at sentence #200000, processed 3926282 words, keeping 255477 word types\n",
      "2020-03-15 08:52:00,183 : INFO : PROGRESS: at sentence #210000, processed 4126206 words, keeping 264242 word types\n",
      "2020-03-15 08:52:00,270 : INFO : PROGRESS: at sentence #220000, processed 4320481 words, keeping 272353 word types\n",
      "2020-03-15 08:52:00,360 : INFO : PROGRESS: at sentence #230000, processed 4512238 words, keeping 280533 word types\n",
      "2020-03-15 08:52:00,502 : INFO : PROGRESS: at sentence #240000, processed 4701580 words, keeping 288698 word types\n",
      "2020-03-15 08:52:00,607 : INFO : PROGRESS: at sentence #250000, processed 4893946 words, keeping 296693 word types\n",
      "2020-03-15 08:52:00,730 : INFO : PROGRESS: at sentence #260000, processed 5084019 words, keeping 304617 word types\n",
      "2020-03-15 08:52:00,840 : INFO : collected 310159 word types from a corpus of 5226851 raw words and 265510 sentences\n",
      "2020-03-15 08:52:00,841 : INFO : Loading a fresh vocabulary\n",
      "2020-03-15 08:52:01,839 : INFO : effective_min_count=1 retains 310159 unique words (100% of original 310159, drops 0)\n",
      "2020-03-15 08:52:01,839 : INFO : effective_min_count=1 leaves 5226851 word corpus (100% of original 5226851, drops 0)\n",
      "2020-03-15 08:52:02,754 : INFO : deleting the raw counts dictionary of 310159 items\n",
      "2020-03-15 08:52:02,759 : INFO : sample=0.001 downsamples 32 most-common words\n",
      "2020-03-15 08:52:02,760 : INFO : downsampling leaves estimated 4128428 word corpus (79.0% of prior 5226851)\n",
      "2020-03-15 08:52:03,073 : INFO : constructing a huffman tree from 310159 words\n",
      "2020-03-15 08:52:13,893 : INFO : built huffman tree with maximum node depth 22\n",
      "2020-03-15 08:52:14,673 : INFO : estimated required memory for 310159 words and 100 dimensions: 589302100 bytes\n",
      "2020-03-15 08:52:14,673 : INFO : resetting layer weights\n",
      "2020-03-15 08:53:26,684 : INFO : training model with 3 workers on 310159 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=3\n",
      "2020-03-15 08:53:27,730 : INFO : EPOCH 1 - PROGRESS: at 5.10% examples, 204888 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:28,792 : INFO : EPOCH 1 - PROGRESS: at 13.02% examples, 259025 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 08:53:29,813 : INFO : EPOCH 1 - PROGRESS: at 21.59% examples, 287001 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:30,814 : INFO : EPOCH 1 - PROGRESS: at 30.05% examples, 303125 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:31,874 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 312782 words/s, in_qsize 5, out_qsize 2\n",
      "2020-03-15 08:53:32,920 : INFO : EPOCH 1 - PROGRESS: at 48.21% examples, 319745 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:53:33,934 : INFO : EPOCH 1 - PROGRESS: at 58.07% examples, 330564 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:34,977 : INFO : EPOCH 1 - PROGRESS: at 67.08% examples, 333674 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:53:35,985 : INFO : EPOCH 1 - PROGRESS: at 76.31% examples, 337478 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:37,007 : INFO : EPOCH 1 - PROGRESS: at 84.90% examples, 338444 words/s, in_qsize 6, out_qsize 2\n",
      "2020-03-15 08:53:38,039 : INFO : EPOCH 1 - PROGRESS: at 93.99% examples, 339881 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 08:53:38,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 08:53:38,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 08:53:38,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 08:53:38,774 : INFO : EPOCH - 1 : training on 5226851 raw words (4128623 effective words) took 12.1s, 341732 effective words/s\n",
      "2020-03-15 08:53:39,826 : INFO : EPOCH 2 - PROGRESS: at 9.47% examples, 375250 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:40,871 : INFO : EPOCH 2 - PROGRESS: at 18.64% examples, 367896 words/s, in_qsize 5, out_qsize 1\n",
      "2020-03-15 08:53:41,926 : INFO : EPOCH 2 - PROGRESS: at 26.66% examples, 351608 words/s, in_qsize 6, out_qsize 2\n",
      "2020-03-15 08:53:42,941 : INFO : EPOCH 2 - PROGRESS: at 34.66% examples, 345351 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:43,951 : INFO : EPOCH 2 - PROGRESS: at 44.03% examples, 351192 words/s, in_qsize 6, out_qsize 0\n",
      "2020-03-15 08:53:44,953 : INFO : EPOCH 2 - PROGRESS: at 52.62% examples, 351847 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:53:46,013 : INFO : EPOCH 2 - PROGRESS: at 61.84% examples, 352627 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:47,039 : INFO : EPOCH 2 - PROGRESS: at 70.06% examples, 348855 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:48,055 : INFO : EPOCH 2 - PROGRESS: at 78.89% examples, 349831 words/s, in_qsize 6, out_qsize 2\n",
      "2020-03-15 08:53:49,062 : INFO : EPOCH 2 - PROGRESS: at 88.28% examples, 352511 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 08:53:50,083 : INFO : EPOCH 2 - PROGRESS: at 98.48% examples, 357164 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:50,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 08:53:50,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 08:53:50,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 08:53:50,279 : INFO : EPOCH - 2 : training on 5226851 raw words (4127835 effective words) took 11.5s, 358860 effective words/s\n",
      "2020-03-15 08:53:51,286 : INFO : EPOCH 3 - PROGRESS: at 8.89% examples, 368760 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:52,339 : INFO : EPOCH 3 - PROGRESS: at 17.87% examples, 359244 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:53,349 : INFO : EPOCH 3 - PROGRESS: at 26.48% examples, 358335 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:53:54,382 : INFO : EPOCH 3 - PROGRESS: at 35.83% examples, 362390 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:53:55,402 : INFO : EPOCH 3 - PROGRESS: at 45.58% examples, 367168 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:56,426 : INFO : EPOCH 3 - PROGRESS: at 55.48% examples, 372967 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 08:53:57,430 : INFO : EPOCH 3 - PROGRESS: at 64.56% examples, 372341 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:53:58,447 : INFO : EPOCH 3 - PROGRESS: at 73.41% examples, 369471 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 08:53:59,473 : INFO : EPOCH 3 - PROGRESS: at 83.35% examples, 372902 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:54:00,484 : INFO : EPOCH 3 - PROGRESS: at 92.45% examples, 371722 words/s, in_qsize 6, out_qsize 0\n",
      "2020-03-15 08:54:01,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 08:54:01,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 08:54:01,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 08:54:01,241 : INFO : EPOCH - 3 : training on 5226851 raw words (4128362 effective words) took 11.0s, 376677 effective words/s\n",
      "2020-03-15 08:54:02,250 : INFO : EPOCH 4 - PROGRESS: at 9.08% examples, 378064 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:03,255 : INFO : EPOCH 4 - PROGRESS: at 18.06% examples, 372710 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:04,278 : INFO : EPOCH 4 - PROGRESS: at 27.80% examples, 381296 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:05,306 : INFO : EPOCH 4 - PROGRESS: at 37.36% examples, 382115 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:54:06,356 : INFO : EPOCH 4 - PROGRESS: at 47.08% examples, 380640 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:54:07,377 : INFO : EPOCH 4 - PROGRESS: at 56.49% examples, 380517 words/s, in_qsize 6, out_qsize 0\n",
      "2020-03-15 08:54:08,399 : INFO : EPOCH 4 - PROGRESS: at 66.48% examples, 383388 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:09,401 : INFO : EPOCH 4 - PROGRESS: at 74.94% examples, 377982 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:10,451 : INFO : EPOCH 4 - PROGRESS: at 84.71% examples, 378571 words/s, in_qsize 6, out_qsize 0\n",
      "2020-03-15 08:54:11,458 : INFO : EPOCH 4 - PROGRESS: at 93.99% examples, 377816 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:12,075 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 08:54:12,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 08:54:12,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 08:54:12,103 : INFO : EPOCH - 4 : training on 5226851 raw words (4129152 effective words) took 10.9s, 380411 effective words/s\n",
      "2020-03-15 08:54:13,135 : INFO : EPOCH 5 - PROGRESS: at 9.47% examples, 382862 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:14,172 : INFO : EPOCH 5 - PROGRESS: at 18.83% examples, 376726 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:54:15,232 : INFO : EPOCH 5 - PROGRESS: at 27.99% examples, 371819 words/s, in_qsize 6, out_qsize 2\n",
      "2020-03-15 08:54:16,236 : INFO : EPOCH 5 - PROGRESS: at 37.93% examples, 380872 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:17,267 : INFO : EPOCH 5 - PROGRESS: at 47.84% examples, 382699 words/s, in_qsize 4, out_qsize 1\n",
      "2020-03-15 08:54:18,312 : INFO : EPOCH 5 - PROGRESS: at 56.89% examples, 378105 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:19,328 : INFO : EPOCH 5 - PROGRESS: at 65.33% examples, 372878 words/s, in_qsize 3, out_qsize 2\n",
      "2020-03-15 08:54:20,371 : INFO : EPOCH 5 - PROGRESS: at 74.94% examples, 372734 words/s, in_qsize 5, out_qsize 0\n",
      "2020-03-15 08:54:21,411 : INFO : EPOCH 5 - PROGRESS: at 84.13% examples, 371704 words/s, in_qsize 6, out_qsize 2\n",
      "2020-03-15 08:54:22,469 : INFO : EPOCH 5 - PROGRESS: at 93.99% examples, 372143 words/s, in_qsize 5, out_qsize 2\n",
      "2020-03-15 08:54:23,133 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 08:54:23,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 08:54:23,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 08:54:23,163 : INFO : EPOCH - 5 : training on 5226851 raw words (4128930 effective words) took 11.1s, 373388 effective words/s\n",
      "2020-03-15 08:54:23,164 : INFO : training on a 26134255 raw words (20642902 effective words) took 56.5s, 365502 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# import modules & set up logging\n",
    "import logging\n",
    "import os\n",
    "from gensim.models import word2vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = word2vec.LineSentence('./zztj_segment.txt') \n",
    "\n",
    "model = word2vec.Word2Vec(sentences, hs=1,min_count=1,window=3,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美 0.5959047079086304\n",
      "义 0.5817850232124329\n",
      "三王 0.5744726657867432\n",
      "穷寇 0.5693146586418152\n",
      "讳 0.5687198638916016\n",
      "舅 0.5630996823310852\n",
      "废而 0.5621340274810791\n",
      "苟 0.5610599517822266\n",
      "之功 0.5607753396034241\n",
      "往者 0.5560637712478638\n",
      "本初 0.5534076690673828\n",
      "敬 0.5516141057014465\n",
      "厚薄 0.5509395599365234\n",
      "智者 0.5492642521858215\n",
      "念 0.5481255650520325\n",
      "儒者 0.5468451976776123\n",
      "虽 0.5464262962341309\n",
      "笃 0.5449784994125366\n",
      "诚实 0.5448262691497803\n",
      "刑政 0.5435634851455688\n",
      "贤 0.5418087244033813\n",
      "岂 0.5402157306671143\n",
      "虽死 0.5394847989082336\n",
      "忠 0.5394835472106934\n",
      "洪尚 0.5382896661758423\n",
      "悖 0.5373016595840454\n",
      "延己 0.5356771349906921\n",
      "咎 0.5332942008972168\n",
      "为念 0.5320184826850891\n",
      "人言 0.5307120084762573\n",
      "虞 0.529837965965271\n",
      "友 0.528887152671814\n",
      "色 0.5276699066162109\n",
      "慎 0.526714026927948\n",
      "存否 0.5266865491867065\n",
      "而慎 0.5266596674919128\n",
      "善人 0.5256220102310181\n",
      "贵 0.5254400968551636\n",
      "勇 0.5239773988723755\n",
      "小女 0.5230116844177246\n",
      "图存 0.5225306749343872\n",
      "国士之 0.5224961638450623\n",
      "微子 0.5218380689620972\n",
      "山水 0.521371603012085\n",
      "宜伐 0.5210088491439819\n",
      "异同 0.5203847885131836\n",
      "异 0.520172119140625\n",
      "死生 0.5197904706001282\n",
      "一君 0.5185272693634033\n",
      "失信 0.5184913277626038\n"
     ]
    }
   ],
   "source": [
    "req_count = 50\n",
    "for key in model.wv.similar_by_word('德', topn =100):\n",
    "    #if len(key[0])==2:\n",
    "        req_count -= 1\n",
    "        print (key[0] ,key[1])\n",
    "        if req_count == 0:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

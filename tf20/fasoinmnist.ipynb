{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import  datetime\n",
    "from    matplotlib import pyplot as plt\n",
    "import  io\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid(images):\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title='name')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "  \n",
    "  return figure\n",
    "\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz, drop_remainder=True) \n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir) \n",
    "\n",
    "# get x from (x,y)\n",
    "sample_img = next(iter(db))[0]\n",
    "# get first image instance\n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample:\", sample_img, step=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.3516905307769775\n",
      "0 meter loss: 2.3516905\n",
      "0 Evaluate Acc: 0.1084735576923077 0.108473554\n",
      "y-pred:[6] y-true:[9]\n",
      "100 loss: 0.29200220108032227\n",
      "100 meter loss: 0.53551096\n",
      "200 loss: 0.21641530096530914\n",
      "200 meter loss: 0.23084775\n",
      "300 loss: 0.16757379472255707\n",
      "300 meter loss: 0.21508314\n",
      "400 loss: 0.05037211626768112\n",
      "400 meter loss: 0.18296458\n",
      "500 loss: 0.22670984268188477\n",
      "500 meter loss: 0.17811401\n",
      "500 Evaluate Acc: 0.960136217948718 0.5343049\n",
      "y-pred:[9] y-true:[9]\n",
      "600 loss: 0.14332233369350433\n",
      "600 meter loss: 0.13411404\n",
      "700 loss: 0.17098259925842285\n",
      "700 meter loss: 0.13143978\n",
      "800 loss: 0.11498280614614487\n",
      "800 meter loss: 0.14036606\n",
      "900 loss: 0.0847308561205864\n",
      "900 meter loss: 0.1318303\n",
      "1000 loss: 0.1547672152519226\n",
      "1000 meter loss: 0.115541056\n",
      "1000 Evaluate Acc: 0.9637419871794872 0.6774506\n",
      "y-pred:[9] y-true:[9]\n",
      "1100 loss: 0.08911725133657455\n",
      "1100 meter loss: 0.10993978\n",
      "1200 loss: 0.10453082621097565\n",
      "1200 meter loss: 0.11841993\n",
      "1300 loss: 0.057773008942604065\n",
      "1300 meter loss: 0.10228972\n",
      "1400 loss: 0.06668175756931305\n",
      "1400 meter loss: 0.10288379\n",
      "1500 loss: 0.054788414388895035\n",
      "1500 meter loss: 0.0885397\n",
      "1500 Evaluate Acc: 0.9697516025641025 0.75052583\n",
      "y-pred:[9] y-true:[9]\n",
      "1600 loss: 0.040012627840042114\n",
      "1600 meter loss: 0.09439155\n",
      "1700 loss: 0.2638343870639801\n",
      "1700 meter loss: 0.10480676\n",
      "1800 loss: 0.0810660570859909\n",
      "1800 meter loss: 0.096099205\n",
      "1900 loss: 0.1152372658252716\n",
      "1900 meter loss: 0.091055825\n",
      "2000 loss: 0.08687864243984222\n",
      "2000 meter loss: 0.08020518\n",
      "2000 Evaluate Acc: 0.9541266025641025 0.791246\n",
      "y-pred:[9] y-true:[9]\n",
      "2100 loss: 0.07264502346515656\n",
      "2100 meter loss: 0.1012588\n",
      "2200 loss: 0.05157695710659027\n",
      "2200 meter loss: 0.108120345\n",
      "2300 loss: 0.07013370841741562\n",
      "2300 meter loss: 0.1157372\n",
      "2400 loss: 0.14525024592876434\n",
      "2400 meter loss: 0.10057643\n",
      "2500 loss: 0.06140211597084999\n",
      "2500 meter loss: 0.08250469\n",
      "2500 Evaluate Acc: 0.9733573717948718 0.8215979\n",
      "y-pred:[9] y-true:[9]\n",
      "2600 loss: 0.036865346133708954\n",
      "2600 meter loss: 0.08083104\n",
      "2700 loss: 0.012755187228322029\n",
      "2700 meter loss: 0.0908372\n",
      "2800 loss: 0.1376856118440628\n",
      "2800 meter loss: 0.07847863\n",
      "2900 loss: 0.09956124424934387\n",
      "2900 meter loss: 0.064070016\n",
      "3000 loss: 0.10043460875749588\n",
      "3000 meter loss: 0.07309843\n",
      "3000 Evaluate Acc: 0.9650440705128205 0.8420902\n",
      "y-pred:[9] y-true:[9]\n",
      "3100 loss: 0.1053198054432869\n",
      "3100 meter loss: 0.08773624\n",
      "3200 loss: 0.07313176989555359\n",
      "3200 meter loss: 0.084600374\n",
      "3300 loss: 0.005494276061654091\n",
      "3300 meter loss: 0.086207725\n",
      "3400 loss: 0.18633989989757538\n",
      "3400 meter loss: 0.063125275\n",
      "3500 loss: 0.03138704225420952\n",
      "3500 meter loss: 0.06414948\n",
      "3500 Evaluate Acc: 0.9735576923076923 0.85852367\n",
      "y-pred:[9] y-true:[9]\n",
      "3600 loss: 0.0676635205745697\n",
      "3600 meter loss: 0.0740886\n",
      "3700 loss: 0.04440019652247429\n",
      "3700 meter loss: 0.07182308\n",
      "3800 loss: 0.28878024220466614\n",
      "3800 meter loss: 0.06858118\n",
      "3900 loss: 0.19700048863887787\n",
      "3900 meter loss: 0.06082753\n",
      "4000 loss: 0.07021357119083405\n",
      "4000 meter loss: 0.057229873\n",
      "4000 Evaluate Acc: 0.9752604166666666 0.8714944\n",
      "y-pred:[9] y-true:[9]\n",
      "4100 loss: 0.04958431422710419\n",
      "4100 meter loss: 0.06722018\n",
      "4200 loss: 0.03333471715450287\n",
      "4200 meter loss: 0.063577086\n",
      "4300 loss: 0.055044688284397125\n",
      "4300 meter loss: 0.050303414\n",
      "4400 loss: 0.01984383538365364\n",
      "4400 meter loss: 0.06415748\n",
      "4500 loss: 0.09259156882762909\n",
      "4500 meter loss: 0.061553348\n",
      "4500 Evaluate Acc: 0.9722556089743589 0.8815705\n",
      "y-pred:[9] y-true:[9]\n",
      "4600 loss: 0.062016356736421585\n",
      "4600 meter loss: 0.06164569\n"
     ]
    }
   ],
   "source": [
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "    \n",
    "        loss_meter.update_state(loss)\n",
    " \n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', float(loss))\n",
    "        with summary_writer.as_default(): \n",
    "            tf.summary.scalar('train-loss', float(loss), step=step) \n",
    "            \n",
    "        print(step,'meter loss:', loss_meter.result().numpy()) \n",
    "        loss_meter.reset_states()\n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        \n",
    "        network.save_weights('weight/weights-{}.ckpt'.format(step))\n",
    "        \n",
    "        total, total_correct = 0., 0\n",
    "\n",
    "        for _, (x, y) in enumerate(ds_val):  \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "            \n",
    "            acc_meter.update_state(y, pred)\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total,acc_meter.result().numpy())\n",
    "        \n",
    "        \n",
    "        \n",
    "        val = x[:1]\n",
    "        yval = y[:1]\n",
    "        #print('yval',yval)\n",
    "        valx = tf.reshape(val, [-1, 28*28])\n",
    "        vout = network(valx) \n",
    "        vpred = tf.argmax(vout, axis=1) \n",
    "        vpred = tf.cast(vpred, dtype=tf.int32)\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('y-pred', float(vpred), step=step)\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('y-true', float(yval), step=step)\n",
    "            print('y-pred:{} y-true:{}'.format(vpred,yval));\n",
    "            #tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "            val_images = tf.reshape(val, [1, 28, 28,1])\n",
    "            #figure  = image_grid(val_images)\n",
    "            tf.summary.image('val-images:', val_images, step=step)\n",
    "\n",
    "        \n",
    "#         # print(x.shape) \n",
    "#         val_images = x[:25]\n",
    "#         val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "#         with summary_writer.as_default():\n",
    "#             tf.summary.scalar('test-acc', float(total_correct/total), step=step)\n",
    "#             #tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "#             val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "#             figure  = image_grid(val_images)\n",
    "#             tf.summary.image('val-images:', plot_to_image(figure), step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x146851b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_weights('weight/weights-4500.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vpred 5.0 y 5.0\n"
     ]
    }
   ],
   "source": [
    "val = x[:1]\n",
    "yval = y[:1]\n",
    "#print('yval',yval)\n",
    "valx = tf.reshape(val, [-1, 28*28])\n",
    "vout = network(valx) \n",
    "vpred = tf.argmax(vout, axis=1) \n",
    "vpred = tf.cast(vpred, dtype=tf.int32)\n",
    "print('vpred',float(vpred),'y',float(yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_images = tf.reshape(val, [1, 28, 28])\n",
    "valxx = val_images.numpy()\n",
    "print(valxx.shape)\n",
    "plt.imshow(valxx[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.315808057785034\n",
      "0 Evaluate Acc: 0.10186298076923077\n",
      "y-pred:[8] y-true:[9]\n",
      "100 loss: 0.16561239957809448\n",
      "200 loss: 0.3528538942337036\n",
      "300 loss: 0.23185959458351135\n",
      "400 loss: 0.14589527249336243\n",
      "500 loss: 0.134721040725708\n",
      "500 Evaluate Acc: 0.9574318910256411\n",
      "y-pred:[9] y-true:[9]\n",
      "600 loss: 0.16056637465953827\n",
      "700 loss: 0.11513088643550873\n",
      "800 loss: 0.0944427028298378\n",
      "900 loss: 0.0788157731294632\n",
      "1000 loss: 0.05569750443100929\n",
      "1000 Evaluate Acc: 0.9637419871794872\n",
      "y-pred:[5] y-true:[9]\n",
      "1100 loss: 0.03666335344314575\n",
      "1200 loss: 0.061334677040576935\n",
      "1300 loss: 0.11887970566749573\n",
      "1400 loss: 0.12095364183187485\n",
      "1500 loss: 0.06874600052833557\n",
      "1500 Evaluate Acc: 0.9685496794871795\n",
      "y-pred:[9] y-true:[9]\n",
      "1600 loss: 0.10840797424316406\n",
      "1700 loss: 0.05040285736322403\n",
      "1800 loss: 0.0959354043006897\n",
      "1900 loss: 0.03953297436237335\n",
      "2000 loss: 0.17798510193824768\n",
      "2000 Evaluate Acc: 0.9730568910256411\n",
      "y-pred:[9] y-true:[9]\n",
      "2100 loss: 0.07479654252529144\n",
      "2200 loss: 0.17055003345012665\n",
      "2300 loss: 0.0984630137681961\n",
      "2400 loss: 0.10341529548168182\n",
      "2500 loss: 0.11772090196609497\n",
      "2500 Evaluate Acc: 0.9699519230769231\n",
      "y-pred:[9] y-true:[9]\n",
      "2600 loss: 0.04261655732989311\n",
      "2700 loss: 0.06308745592832565\n",
      "2800 loss: 0.07615071535110474\n",
      "2900 loss: 0.04591050744056702\n",
      "3000 loss: 0.07324615120887756\n",
      "3000 Evaluate Acc: 0.9689503205128205\n",
      "y-pred:[5] y-true:[9]\n",
      "3100 loss: 0.08547253161668777\n",
      "3200 loss: 0.012857647612690926\n",
      "3300 loss: 0.09350673109292984\n",
      "3400 loss: 0.06246225908398628\n",
      "3500 loss: 0.0794573724269867\n",
      "3500 Evaluate Acc: 0.9738581730769231\n",
      "y-pred:[9] y-true:[9]\n",
      "3600 loss: 0.08437887579202652\n",
      "3700 loss: 0.13555343449115753\n",
      "3800 loss: 0.058249302208423615\n",
      "3900 loss: 0.06747670471668243\n",
      "4000 loss: 0.08441154658794403\n",
      "4000 Evaluate Acc: 0.9709535256410257\n",
      "y-pred:[5] y-true:[9]\n",
      "4100 loss: 0.03193691000342369\n",
      "4200 loss: 0.0410149022936821\n",
      "4300 loss: 0.1319398283958435\n",
      "4400 loss: 0.09269502758979797\n",
      "4500 loss: 0.16217757761478424\n",
      "4500 Evaluate Acc: 0.9738581730769231\n",
      "y-pred:[9] y-true:[9]\n",
      "4600 loss: 0.1223548948764801\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "import  datetime\n",
    "from    matplotlib import pyplot as plt\n",
    "import  io\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid(images):\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title='name')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "  \n",
    "  return figure\n",
    "\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz, drop_remainder=True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir) \n",
    "\n",
    "# get x from (x,y)\n",
    "sample_img = next(iter(db))[0]\n",
    "# get first image instance\n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample:\", sample_img, step=0)\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    " \n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', float(loss))\n",
    "        with summary_writer.as_default(): \n",
    "            tf.summary.scalar('train-loss', float(loss), step=step) \n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        \n",
    "        network.save_weights('weight/weights-{}.ckpt'.format(step))\n",
    "        \n",
    "        total, total_correct = 0., 0\n",
    "\n",
    "        for _, (x, y) in enumerate(ds_val):  \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total)\n",
    "        \n",
    "        val = x[:1]\n",
    "        yval = y[:1]\n",
    "        #print('yval',yval)\n",
    "        valx = tf.reshape(val, [-1, 28*28])\n",
    "        vout = network(valx) \n",
    "        vpred = tf.argmax(vout, axis=1) \n",
    "        vpred = tf.cast(vpred, dtype=tf.int32)\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('y-pred', float(vpred), step=step)\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('y-true', float(yval), step=step)\n",
    "            print('y-pred:{} y-true:{}'.format(vpred,yval));\n",
    "            #tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "            val_images = tf.reshape(val, [1, 28, 28,1])\n",
    "            #figure  = image_grid(val_images)\n",
    "            tf.summary.image('val-images:', val_images, step=step)\n",
    "\n",
    "        \n",
    "#         # print(x.shape) \n",
    "#         val_images = x[:25]\n",
    "#         val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "#         with summary_writer.as_default():\n",
    "#             tf.summary.scalar('test-acc', float(total_correct/total), step=step)\n",
    "#             #tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)\n",
    "            \n",
    "#             val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "#             figure  = image_grid(val_images)\n",
    "#             tf.summary.image('val-images:', plot_to_image(figure), step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
